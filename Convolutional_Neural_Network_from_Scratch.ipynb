{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD3Ak0s+heAl0pedgvf2Vi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saranshikens/Basic-ML/blob/main/Convolutional_Neural_Network_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPLEMENTING CONVOLUTIONAL NEURAL NETWORK FROM SCRATCH**"
      ],
      "metadata": {
        "id": "1wH9z5oYtAE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTATIONS**  \n",
        "I * K - convolution  \n",
        "I $\\times$ K - cross correlation"
      ],
      "metadata": {
        "id": "L5YyJEnxyfqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**$\\large \\text{INPUT IMAGE}$**"
      ],
      "metadata": {
        "id": "JojPj8KRG4g5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{Let the depth of input be 3 and their width be 3 as well, then the input matrices will look like below.}\\\\\n",
        "........X_1.......\\\\\n",
        "\\begin{bmatrix}\n",
        "x_{11}^1 & x_{12}^1 & x_{13}^1 \\\\\n",
        "x_{21}^1 & x_{22}^1 & x_{23}^1 \\\\\n",
        "x_{31}^1 & x_{32}^1 & x_{33}^1\n",
        "\\end{bmatrix} \\\\\n",
        "........X_2.......\\\\\n",
        "\\begin{bmatrix}\n",
        "x_{11}^2 & x_{12}^2 & x_{13}^2 \\\\\n",
        "x_{21}^2 & x_{22}^2 & x_{23}^2 \\\\\n",
        "x_{31}^2 & x_{32}^2 & x_{33}^2\n",
        "\\end{bmatrix} \\\\\n",
        "........X_3.......\\\\\n",
        "\\begin{bmatrix}\n",
        "x_{11}^3 & x_{12}^3 & x_{13}^3 \\\\\n",
        "x_{21}^3 & x_{22}^3 & x_{23}^3 \\\\\n",
        "x_{31}^3 & x_{32}^3 & x_{33}^3\n",
        "\\end{bmatrix}$"
      ],
      "metadata": {
        "id": "4j9BSphxGw-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**$\\large \\text{KERNELS}$**"
      ],
      "metadata": {
        "id": "0ncX4zniHKm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{The depth of kernels will be equal to that of input. Let there be 2 kernels, each having a size of 2.}\\\\\n",
        "....K_{11}........K_{21}....\\\\\n",
        "\\begin{bmatrix}\n",
        "k_{11}^1 & k_{12}^1 \\\\\n",
        "k_{21}^1 & k_{22}^1\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "k_{11}^1 & k_{12}^1 \\\\\n",
        "k_{21}^1 & k_{22}^1\n",
        "\\end{bmatrix} \\\\\n",
        "....K_{12}........K_{22}....\\\\\n",
        "\\begin{bmatrix}\n",
        "k_{11}^2 & k_{12}^2 \\\\\n",
        "k_{21}^2 & k_{22}^2\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "k_{11}^2 & k_{12}^2 \\\\\n",
        "k_{21}^2 & k_{22}^2\n",
        "\\end{bmatrix} \\\\\n",
        "....K_{13}........K_{23}....\\\\\n",
        "\\begin{bmatrix}\n",
        "k_{11}^3 & k_{12}^3 \\\\\n",
        "k_{21}^3 & k_{22}^3\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "k_{11}^3 & k_{12}^3 \\\\\n",
        "k_{21}^3 & k_{22}^3\n",
        "\\end{bmatrix}$"
      ],
      "metadata": {
        "id": "538Dw2NGHFVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**$\\large \\text{BIASES}$**"
      ],
      "metadata": {
        "id": "i-o_2unMHrH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{The depth of biases will always be 1. The number and size of biases will be equal to that of the kernels.}\\\\\n",
        "....B_{1}.........B_{2}....\\\\\n",
        "\\begin{bmatrix}\n",
        "b_{11}^1 & b_{12}^1 \\\\\n",
        "b_{21}^1 & b_{22}^1\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "b_{11}^2 & b_{12}^2 \\\\\n",
        "b_{21}^2 & b_{22}^2\n",
        "\\end{bmatrix}$"
      ],
      "metadata": {
        "id": "n2ZiMexqH3Qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**$\\large \\text{OUTPUT}$**"
      ],
      "metadata": {
        "id": "JwDRM9IhIFoo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{The depth of output will be equal to the number of kernels. The size of output will be equal to that of the kernels.}\\\\\n",
        "....Y_1.....\\\\\n",
        "\\begin{bmatrix}\n",
        "y_{11}^1 & y_{12}^1 \\\\\n",
        "y_{21}^1 & y_{22}^1\n",
        "\\end{bmatrix}\\\\\n",
        "....Y_2.....\\\\\n",
        "\\begin{bmatrix}\n",
        "y_{11}^2 & y_{12}^2 \\\\\n",
        "y_{21}^2 & y_{22}^2\n",
        "\\end{bmatrix}$"
      ],
      "metadata": {
        "id": "aBmmTjQPIJ-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FORWARD PROPAGATION**   \n",
        "Let us generalize the above situation.  \n",
        "Let depth of input be d, and number of input matrices be n.     \n",
        "$Y_1 = B_1 + X_1 \\times K_{11} + ⋯ + X_n \\times K_{1n}$  \n",
        "$Y_2 = B_2 + X_1 \\times K_{21} + ⋯ + X_n \\times K_{2n}$  \n",
        ".  \n",
        ".  \n",
        ".  \n",
        "$Y_d = B_d + X_1 \\times K_{11} + ⋯ + X_n \\times K_{1n}$  \n",
        "So, $Y_i = B_i + \\displaystyle \\sum_{j=1}^n X_j \\times K_{ij}$, $i=1, 2 , ..., d$.  "
      ],
      "metadata": {
        "id": "O5XYS-NH8aim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BACKWARD PROPAGATION**  \n",
        "Let $E$ be the cross entropy loss. Then we need to compute $\\dfrac{\\partial{E}}{\\partial{K_{ij}}}$, $\\dfrac{\\partial{E}}{\\partial{B_i}}$ and $\\dfrac{\\partial{E}}{\\partial{X_j}}$.  "
      ],
      "metadata": {
        "id": "2EGHpdbq-B40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COMPUTING $\\dfrac{\\partial{E}}{\\partial{K_{ij}}}$**  \n",
        "Let us consider a simple case first, $Y_i = B_i + X_1 \\times K_{i1}$.  \n",
        "$y_{11} = b_{11} + k_{11}x_{11} + k_{12}x_{12} + k_{21}x_{21} + k_{22}x_{22}$  \n",
        "$y_{12} = b_{12} + k_{11}x_{12} + k_{12}x_{21} + k_{21}x_{22} + k_{22}x_{23}$  \n",
        "$y_{21} = b_{21} + k_{11}x_{21} + k_{12}x_{22} + k_{21}x_{31} + k_{22}x_{32}$  \n",
        "$y_{22} = b_{22} + k_{11}x_{22} + k_{12}x_{23} + k_{21}x_{32} + k_{22}x_{33}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{k_{11}}} =  \\dfrac{\\partial{E}}{\\partial{y_{11}}} x_{11} + \\dfrac{\\partial{E}}{\\partial{y_{12}}} x_{12} + \\dfrac{\\partial{E}}{\\partial{y_{21}}} x_{21} + \\dfrac{\\partial{E}}{\\partial{y_{22}}} x_{22}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{k_{12}}} =  \\dfrac{\\partial{E}}{\\partial{y_{11}}} x_{12} + \\dfrac{\\partial{E}}{\\partial{y_{12}}} x_{13} + \\dfrac{\\partial{E}}{\\partial{y_{21}}} x_{22} + \\dfrac{\\partial{E}}{\\partial{y_{22}}} x_{23}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{k_{21}}} =  \\dfrac{\\partial{E}}{\\partial{y_{11}}} x_{21} + \\dfrac{\\partial{E}}{\\partial{y_{12}}} x_{22} + \\dfrac{\\partial{E}}{\\partial{y_{21}}} x_{31} + \\dfrac{\\partial{E}}{\\partial{y_{22}}} x_{32}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{k_{22}}} =  \\dfrac{\\partial{E}}{\\partial{y_{11}}} x_{22} + \\dfrac{\\partial{E}}{\\partial{y_{12}}} x_{23} + \\dfrac{\\partial{E}}{\\partial{y_{21}}} x_{32} + \\dfrac{\\partial{E}}{\\partial{y_{22}}} x_{33}$   \n",
        "\n",
        "Generalizing this gives us that, $\\dfrac{\\partial{E}}{\\partial{K}} = X \\times \\dfrac{\\partial{E}}{\\partial{Y}}$.  \n",
        "So, $\\dfrac{\\partial{E}}{\\partial{K_{ij}}} = X_j \\times \\dfrac{\\partial{E}}{\\partial{Y_i}}$."
      ],
      "metadata": {
        "id": "htL2wSnp-x5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COMPUTING $\\dfrac{\\partial{E}}{\\partial{B_i}}$**  \n",
        "$\\dfrac{\\partial{E}}{\\partial{b_{11}}} = \\dfrac{\\partial{E}}{\\partial{y_{11}}}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{b_{12}}} = \\dfrac{\\partial{E}}{\\partial{y_{12}}}$   \n",
        "$\\dfrac{\\partial{E}}{\\partial{b_{21}}} = \\dfrac{\\partial{E}}{\\partial{y_{21}}}$   \n",
        "$\\dfrac{\\partial{E}}{\\partial{b_{22}}} = \\dfrac{\\partial{E}}{\\partial{y_{22}}}$  \n",
        "Generalizing this gives us that $\\dfrac{\\partial{E}}{\\partial{B}} = \\dfrac{\\partial{E}}{\\partial{Y}}$.  \n",
        "So, $\\dfrac{\\partial{E}}{\\partial{B_i}} = \\dfrac{\\partial{E}}{\\partial{Y_i}}$    "
      ],
      "metadata": {
        "id": "JOF3PrY-EPu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COMPUTING $\\dfrac{\\partial{E}}{\\partial{X_j}}$**  \n",
        "$\\dfrac{\\partial{E}}{\\partial{x_{11}}} = \\dfrac{\\partial{E}}{\\partial{y_{11}}} k_{11}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{x_{12}}} = \\dfrac{\\partial{E}}{\\partial{y_{11}}} k_{12} + \\dfrac{\\partial{E}}{\\partial{y_{12}}} k_{11}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{x_{13}}} = \\dfrac{\\partial{E}}{\\partial{y_{12}}} k_{12}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{x_{21}}} = \\dfrac{\\partial{E}}{\\partial{y_{11}}} k_{21} + \\dfrac{\\partial{E}}{\\partial{y_{21}}} k_{11}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{x_{22}}} = \\dfrac{\\partial{E}}{\\partial{y_{11}}} k_{22} + \\dfrac{\\partial{E}}{\\partial{y_{12}}} k_{21} + \\dfrac{\\partial{E}}{\\partial{y_{21}}} k_{12} + \\dfrac{\\partial{E}}{\\partial{y_{22}}} k_{11}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{x_{23}}} = \\dfrac{\\partial{E}}{\\partial{y_{12}}} k_{22} + \\dfrac{\\partial{E}}{\\partial{y_{22}}} k_{12}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{x_{31}}} = \\dfrac{\\partial{E}}{\\partial{y_{21}}} k_{21}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{x_{32}}} = \\dfrac{\\partial{E}}{\\partial{y_{21}}} k_{22} + \\dfrac{\\partial{E}}{\\partial{y_{22}}} k_{21}$  \n",
        "$\\dfrac{\\partial{E}}{\\partial{x_{33}}} = \\dfrac{\\partial{E}}{\\partial{y_{22}}} k_{22}$  \n",
        "Generalising this gives us that $\\dfrac{\\partial{E}}{\\partial{X}} = \\dfrac{\\partial{E}}{\\partial{Y}} \\underset{\\text{full}}{*} K$.  \n",
        "$\\dfrac{\\partial{E}}{\\partial{X_j}} = \\displaystyle \\sum_{i=1}^d \\dfrac{\\partial{E}}{\\partial{Y_i}} \\underset{\\text{full}}{*} K_{ij}$, $j=1,2,...,n$."
      ],
      "metadata": {
        "id": "fTokn7IjFc0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNGaTKdJhBPY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.signal import convolve, correlate\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACTIVATION FUNCTIONS**"
      ],
      "metadata": {
        "id": "OxfQxiLrh7-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU(X):\n",
        "  return np.maximum(0, X)\n",
        "def ReLU_deriv(X):\n",
        "  return X>=0"
      ],
      "metadata": {
        "id": "fmTiL5Lzh-_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOFTMAX AND CROSS ENTROPY**"
      ],
      "metadata": {
        "id": "3pmDX4hEi47q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(X):\n",
        "  return np.exp(X)/np.sum(np.exp(X))\n",
        "def cross_entropy(pred, label):\n",
        "  return -np.log(pred[label]+1e-9)\n",
        "def cross_entropy_grad(pred, label):\n",
        "  grad = pred.copy()\n",
        "  grad[label] -= 1\n",
        "  return grad"
      ],
      "metadata": {
        "id": "330WkjnviMaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONVOLUTIONAL LAYER**"
      ],
      "metadata": {
        "id": "Q4RTda5Wi9i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLayer:\n",
        "  def __init__(self, num_filters, filter_size, input_depth):\n",
        "    self.num_filters = num_filters\n",
        "    self.filter_size = filter_size\n",
        "    self.input_depth = input_depth\n",
        "    self.filters = np.random.randn(num_filters, input_depth, filter_size, filter_size)*0.1\n",
        "    self.biases = np.zeros(num_filters)\n",
        "\n",
        "  def forward_prop(self, X):\n",
        "    self.last_input = X\n",
        "    depth, height, width = X.shape\n",
        "    self.output = np.zeros((self.num_filters, height-self.filter_size+1, width-self.filter_size+1))\n",
        "\n",
        "    for f in range(self.num_filters):\n",
        "      for i in range(self.input_depth):\n",
        "        self.output[f] += convolve(X[i], self.filters[f, i], mode='valid')\n",
        "      self.output[f]+=self.biases[f]\n",
        "    return self.output\n",
        "\n",
        "  def backward_prop(self, d_out, lr):\n",
        "    d_filters = np.zeros_like(self.filters)\n",
        "    d_input = np.zeros_like(self.last_input)\n",
        "\n",
        "    for f in range(self.num_filters):\n",
        "      for d in range(self.input_depth):\n",
        "        d_filters[f, d] = correlate(self.last_input[d], d_out[f], mode='valid')\n",
        "        d_input[d] += convolve(d_out[f], self.filters[f, d][::-1, ::-1], mode='full')\n",
        "      self.biases[f] -= lr * np.sum(d_out[f])\n",
        "    self.filters -= lr * d_filters\n",
        "    return d_input"
      ],
      "metadata": {
        "id": "SnYhaOxIjAcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAX POOLING LAYER**"
      ],
      "metadata": {
        "id": "rUzQMLSxlDcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPoolLayer:\n",
        "  def __init__(self, size):\n",
        "    self.size = size\n",
        "\n",
        "  def forward_prop(self, X):\n",
        "    self.last_input = X\n",
        "    depth, height, width = X.shape\n",
        "    height_out, width_out = height//self.size, width//self.size\n",
        "    out = np.zeros((depth, height_out, width_out))\n",
        "    self.mask = np.zeros_like(X)\n",
        "\n",
        "    for d in range(depth):\n",
        "      for h in range(height_out):\n",
        "        for w in range(width_out):\n",
        "          patch = X[d, h*self.size:(h+1)*self.size, w*self.size:(w+1)*self.size]\n",
        "          max_val = np.max(patch)\n",
        "          out[d, h, w] = max_val\n",
        "          max_pos = np.where(patch == max_val)\n",
        "          self.mask[d, h*self.size+max_pos[0][0], w*self.size+max_pos[1][0]] = 1\n",
        "    return out\n",
        "\n",
        "  def backward_prop(self, d_out):\n",
        "    d_input = np.zeros_like(self.last_input)\n",
        "    depth, height_out, width_out = d_out.shape\n",
        "    for d in range(depth):\n",
        "      for h in range(height_out):\n",
        "        for w in range(width_out):\n",
        "          d_input[d, h*self.size:(h+1)*self.size, w*self.size:(w+1)*self.size] += \\\n",
        "          self.mask[d, h*self.size:(h+1)*self.size, w*self.size:(w+1)*self.size] * d_out[d, h, w]\n",
        "    return d_input"
      ],
      "metadata": {
        "id": "G6xuRXHJlGtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DENSE LAYER**"
      ],
      "metadata": {
        "id": "-A9e8TBdpYPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "  def __init__(self, input_size, output_size):\n",
        "    self.weights = np.random.randn(output_size, input_size)*0.1\n",
        "    self.biases = np.zeros(output_size)\n",
        "\n",
        "  def forward_prop(self, X):\n",
        "    self.last_input = X\n",
        "    return np.dot(self.weights, X) + self.biases\n",
        "\n",
        "  def backward_prop(self, d_out, lr):\n",
        "    d_weights = np.outer(d_out, self.last_input)\n",
        "    d_input = np.dot(self.weights.T, d_out)\n",
        "    self.weights -= lr * d_weights\n",
        "    self.biases -= lr * d_out\n",
        "    return d_input"
      ],
      "metadata": {
        "id": "UL7sRbDUpfdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREPROCESSING THE DATASET**"
      ],
      "metadata": {
        "id": "6-o5hl5dqiAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(n=1000):\n",
        "  mnist = fetch_openml('mnist_784', version=1)\n",
        "  X = mnist.data[:n].to_numpy().astype(np.float32) / 255.0\n",
        "  y = mnist.target[:n].astype(np.int32)\n",
        "  X = X.reshape(-1, 1, 28, 28)\n",
        "  return train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "0WVOcmGWqln2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING THE CNN**"
      ],
      "metadata": {
        "id": "LX_4FsQ3rE-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X_train, y_train, epochs=3, lr=0.01):\n",
        "  conv = ConvLayer(num_filters=4, filter_size=3, input_depth=1)\n",
        "  pool = MaxPoolLayer(size=2)\n",
        "  dense = DenseLayer(input_size=4*13*13, output_size=10)\n",
        "\n",
        "  for e in range(epochs):\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    for i in range(len(X_train)):\n",
        "      x = X_train[i]\n",
        "      label = y_train.iloc[i]\n",
        "\n",
        "      out = conv.forward_prop(x)\n",
        "      out = ReLU(out)\n",
        "      out = pool.forward_prop(out)\n",
        "      out_flat = out.flatten()\n",
        "      out = dense.forward_prop(out_flat)\n",
        "      probs = softmax(out)\n",
        "      loss = cross_entropy(probs, label)\n",
        "      total_loss += loss\n",
        "      if np.argmax(probs) == label:\n",
        "        correct += 1\n",
        "\n",
        "      grad = cross_entropy_grad(probs, label)\n",
        "      grad = dense.backward_prop(grad, lr)\n",
        "      grad = grad.reshape((4,13,13))\n",
        "      grad = pool.backward_prop(grad)\n",
        "      grad = ReLU_deriv(conv.output) *grad\n",
        "      conv.backward_prop(grad, lr)\n",
        "\n",
        "    print(f\"Epoch {e+1}: Loss = {total_loss:.4f}, Accuracy={correct/len(X_train):.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-_eDfsWSrIml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUNNING THE MODEL**"
      ],
      "metadata": {
        "id": "CIycYr79tAN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_dataset(n=1000)\n",
        "train(X_train, y_train, epochs=5, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otLAcSietC6h",
        "outputId": "a22da9fe-72cd-4c65-8eba-f622b5764232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/scipy/signal/_signaltools.py:286: RuntimeWarning: invalid value encountered in cast\n",
            "  z = _sigtools._correlateND(in1, in2, out, val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 1189.2595, Accuracy=0.5012\n",
            "Epoch 2: Loss = 483.4114, Accuracy=0.8125\n",
            "Epoch 3: Loss = 386.8775, Accuracy=0.8512\n",
            "Epoch 4: Loss = 357.8153, Accuracy=0.8638\n",
            "Epoch 5: Loss = 339.6692, Accuracy=0.8775\n"
          ]
        }
      ]
    }
  ]
}